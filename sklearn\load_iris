import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris
from collections import deque
import numpy as np


X = load_iris()
X, y = torch.tensor(X['data'], dtype=torch.float32), torch.tensor(X['target'], dtype=torch.long)

scaler = StandardScaler()
X = scaler.fit_transform(X)
X = torch.tensor(X, dtype=torch.float32)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, shuffle=True)

model = nn.Sequential(nn.Linear(X.size(1), y_size))
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)


def exponential_moving_average(data, alpha):
    ema = deque([])
    ema.append(data[0])

    for i in range(1, len(data)):
        ema.append(alpha * data[i] + (1 - alpha) * ema[i - 1])

    return ema


alpha = 0.3
cumulative_loss = deque([float("inf")])
steps = 0
model.train()
while np.mean(cumulative_loss) > 0.2:
    cumulative_loss.clear()
    for x_tr, y_tr in zip(X_train, y_train):
        predict = model(x_tr)
        loss = criterion(predict, y_tr)

        cumulative_loss.append(loss.item())

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if len(cumulative_loss) > 10:
            cumulative_loss.popleft()
        cumulative_loss = exponential_moving_average(cumulative_loss, alpha)

model.eval()
Q = 0
for x_t, y_t in zip(X_test, y_test):
    predict = model(x_t)
    predicted_class = torch.argmax(predict)
    Q += predicted_class == y_t

accuracy = Q / len(X_test) * 100
print(f"Accuracy: {accuracy:.2f}%")
