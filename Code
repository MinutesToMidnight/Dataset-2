import torch
# from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import KFold
import numpy as np
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from torch.utils.data import DataLoader, TensorDataset


# Загрузка данных из CSV файла
lst = []
class_belong = []
with open("D:\\data_lesson2.csv", "r") as f:
    f.readline()  # Пропускаем заголовок
    lines = f.readline()
    while lines:
        line = list(filter(lambda x: x, lines.strip().split(",")))
        if len(line) != 10:
            lines = f.readline()
            continue
        lst.append(list(map(float, line[:-1])))
        class_belong.append(line[-1])
        lines = f.readline()

# Преобразование списков в numpy массивы
X = np.array(lst)
y = np.array(class_belong)

# Кодирование меток классов в числовые значения
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Стандартизация данных
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Преобразование данных в тензоры PyTorch
X_tensor = torch.tensor(X, dtype=torch.float32)
y_tensor = torch.tensor(y, dtype=torch.long)

kf = KFold(n_splits=7, shuffle=True)

# Определение нейронной сети
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(9, 128)  # 9 признаков
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, 5)  # 5 классов

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = self.fc4(x)
        return x


accuracies = []

for train_index, test_index in kf.split(X):
    X_train, X_test = X_tensor[train_index], X_tensor[test_index]
    y_train, y_test = y_tensor[train_index], y_tensor[test_index]

    train_dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

    # Инициализация модели, критерия и оптимизатора
    model = Net()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.01)

    model.train()
    train_tqdm = tqdm(train_loader, leave=True)
    for x_tr, y_tr in train_tqdm:
        predict = model(x_tr)
        loss = criterion(predict, y_tr)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_tqdm.set_description(f"Loss: {loss.item():.4f}")

    test_dataset = TensorDataset(X_test, y_test)
    test_loader = DataLoader(test_dataset, batch_size=32)

    model.eval()
    Q = 0

    test_tqdm = tqdm(test_loader, leave=True)

    for X_t, y_t in test_tqdm:
        with torch.no_grad():
            predict = model(X_t)
            predict = torch.argmax(predict, dim=1)
            Q += torch.sum(y_t == predict).item()

    Q /= len(X_test)
    accuracies.append(Q)

print(f"Mean accuracy: {np.mean(accuracies)}")

